{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import cloudscraper\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_links(soup):\n",
    "    \"\"\"Takes the soup of a page and returns a list of links to each house\"\"\"\n",
    "    a_tags = soup.find_all('a',class_='sold-property-link js-sold-property-card-link')\n",
    "    return [tag.get('href') for tag in a_tags]\n",
    "\n",
    "def get_houses_info(links:list[str]):\n",
    "    \"\"\"Takes the link to a house and returns a dictionary with the house properties\"\"\"\n",
    "    scraper = cloudscraper.create_scraper()  # returns a CloudScraper instance\n",
    "    \n",
    "    house_properties = []\n",
    "    \n",
    "    for link in links:\n",
    "        html = scraper.get(link).content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        data_raw = json.loads(soup.find('div', class_='sold-property__map js-listing-map-sold')['data-initial-data'])\n",
    "        \n",
    "        data_parsed = {\n",
    "            \"adress\": f\"{data_raw['listing']['streetAddress']}, {data_raw['listing']['area']}, {data_raw['listing']['municipality']['fullName']}\",\n",
    "            \"longitude\": f\"{data_raw['listing']['coordinate'][0]}\",\n",
    "            \"latitude\": f\"{data_raw['listing']['coordinate'][1]}\",\n",
    "            \"living_area\": f\"{data_raw['listing']['livingArea']}\",\n",
    "            \"land_area\": f\"{data_raw['listing']['landArea']}\",\n",
    "            \"supplemental_area\": f\"{data_raw['listing']['supplementalArea']}\",\n",
    "            \"patio\":'1' if 'Uteplats' in [feature['text'] for feature in data_raw['listing']['labels']] else '0',\n",
    "            \"balcony\":'1' if 'Balkong' in [feature['text'] for feature in data_raw['listing']['labels']] else '0',\n",
    "            \"number_of_rooms\": f\"{data_raw['listing']['numberOfRooms']}\",\n",
    "            \"build_year\": re.sub(r\"^\\s+|\\s+$\", \"\", soup.find(\"dl\", class_=\"sold-property__attributes\").find(\"dt\", text=\"Byggår\").find_next_sibling('dd').text) if soup.find(\"dl\", class_=\"sold-property__attributes\").find(\"dt\", text=\"Byggår\") is not None else 'None',\n",
    "            \"operating cost\":' '.join(re.findall(r'\\d+', soup.find(\"dl\", class_=\"sold-property__attributes\").find(\"dt\", text=\"Driftskostnad\").find_next_sibling('dd').text)) if soup.find(\"dl\", class_=\"sold-property__attributes\").find(\"dt\", text=\"Driftskostnad\") is not None else 'None',\n",
    "            \"sold_price\": ' '.join(re.findall(r'\\d+', f\"{data_raw['listing']['sellingPrice']['formatted']}\"))\n",
    "        }\n",
    "        \n",
    "        house_properties.append(data_parsed)\n",
    "        \n",
    "    return house_properties\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "listing_links = [\n",
    "    f\"https://www.hemnet.se/salda/bostader?item_types%5B%5D=villa&page={page}&sold_age=12m\"\n",
    "    for page in range(1, 51)\n",
    "]\n",
    "\n",
    "data_pararell = []\n",
    "\n",
    "def process_listing_page(listing_page):\n",
    "  html = scraper.get(listing_page).content\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "  links = get_house_links(soup)\n",
    "\n",
    "  return get_houses_info(links)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    data_pararell.extend(executor.map(process_listing_page, listing_links))\n",
    "    \n",
    "executor.shutdown(wait=True)\n",
    "\n",
    "flattened_data = list(itertools.chain.from_iterable(data_pararell))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# write the DataFrame to a CSV file\n",
    "df.to_csv('data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b680d763c5648c61f2662d8b7e45cb8d98511a099eb47ced1e7beb7b4bf8e8e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
